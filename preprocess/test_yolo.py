#!/usr/bin/env python3
"""
YOLO -> SAM2 å®Œæ•´æµç¨‹é›†æˆæµ‹è¯•
æµ‹è¯•ä»YOLOæ£€æµ‹åˆ°SAM2åˆ†å‰²çš„å®Œæ•´pipeline
"""

import torch
import numpy as np
import sys
import os
from PIL import Image
import cv2

def load_models():
    """åŠ è½½YOLOå’ŒSAM2æ¨¡å‹"""
    print("ğŸš€ åŠ è½½æ¨¡å‹...")
    
    # 1. åŠ è½½YOLO
    print("1. åŠ è½½YOLO...")
    from ultralytics import YOLO
    yolo_model = YOLO("./yolov8n.pt")
    print("âœ… YOLOåŠ è½½æˆåŠŸ")
    
    # 2. åŠ è½½SAM2
    print("2. åŠ è½½SAM2...")
    # æ·»åŠ SAM2è·¯å¾„
    sys.path.append(os.path.abspath("../sam2"))
    
    from hydra import initialize_config_dir, compose
    from hydra.core.global_hydra import GlobalHydra
    from hydra.utils import instantiate
    from omegaconf import OmegaConf
    from sam2.sam2_image_predictor import SAM2ImagePredictor
    
    # æ¸…é™¤Hydraå®ä¾‹
    if GlobalHydra().is_initialized():
        GlobalHydra.instance().clear()
    
    # åŠ è½½SAM2é…ç½®å’Œæ¨¡å‹
    config_dir = os.path.abspath("../sam2/sam2/configs")
    with initialize_config_dir(config_dir=config_dir, version_base=None):
        cfg = compose(config_name="sam2_hiera_l.yaml")
        OmegaConf.resolve(cfg)
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = instantiate(cfg.model, _recursive_=True)
        
        # åŠ è½½æƒé‡
        model_path = "../local_sam2_hiera_large/sam2_hiera_large.pt"
        checkpoint = torch.load(model_path, map_location="cpu", weights_only=True)
        model.load_state_dict(checkpoint["model"])
        
        model = model.to(device).eval()
        sam_predictor = SAM2ImagePredictor(model)
        print("âœ… SAM2åŠ è½½æˆåŠŸ")
    
    return yolo_model, sam_predictor

def create_test_image_with_objects():
    """åˆ›å»ºåŒ…å«æ˜æ˜¾å¯¹è±¡çš„æµ‹è¯•å›¾åƒ"""
    print("\nğŸ“‹ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
    
    # åˆ›å»ºä¸€ä¸ªæœ‰æ˜æ˜¾å‡ ä½•å½¢çŠ¶çš„å›¾åƒï¼Œæ›´å®¹æ˜“è¢«YOLOæ£€æµ‹
    image = np.ones((640, 640, 3), dtype=np.uint8) * 50  # æ·±ç°èƒŒæ™¯
    
    # æ·»åŠ ä¸€äº›æ˜æ˜¾çš„å½¢çŠ¶
    # çº¢è‰²çŸ©å½¢ (æ¨¡æ‹Ÿè½¦è¾†)
    cv2.rectangle(image, (100, 200), (250, 350), (0, 0, 255), -1)
    
    # è“è‰²åœ†å½¢ (æ¨¡æ‹Ÿçƒç±»)
    cv2.circle(image, (450, 300), 80, (255, 0, 0), -1)
    
    # ç»¿è‰²çŸ©å½¢ (æ¨¡æ‹Ÿå¦ä¸€ä¸ªå¯¹è±¡)
    cv2.rectangle(image, (300, 100), (500, 200), (0, 255, 0), -1)
    
    # æ·»åŠ ä¸€äº›å™ªå£°è®©å›¾åƒæ›´çœŸå®
    noise = np.random.randint(0, 30, image.shape, dtype=np.uint8)
    image = cv2.add(image, noise)
    
    print(f"âœ… åˆ›å»ºæµ‹è¯•å›¾åƒ: {image.shape}")
    return image

def load_real_image(image_path):
    """åŠ è½½çœŸå®å›¾åƒæ–‡ä»¶"""
    print(f"\nğŸ“‹ åŠ è½½çœŸå®å›¾åƒ: {image_path}")
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return None
    
    try:
        # ä½¿ç”¨PILåŠ è½½å›¾åƒ
        pil_image = Image.open(image_path).convert('RGB')
        image_array = np.array(pil_image)
        print(f"âœ… å›¾åƒåŠ è½½æˆåŠŸ: {image_array.shape}")
        return image_array
    except Exception as e:
        print(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
        return None

def test_yolo_detection_with_filter(yolo_model, image, target_classes=['person']):
    """æµ‹è¯•YOLOæ£€æµ‹ï¼Œåªä¿ç•™æŒ‡å®šç±»åˆ«"""
    print(f"\nğŸ“‹ Step 1: YOLOç›®æ ‡æ£€æµ‹ (ç­›é€‰ç±»åˆ«: {target_classes})...")
    
    # YOLOæ¨ç†
    results = yolo_model(image, verbose=False)
    
    # è§£ææ£€æµ‹ç»“æœï¼Œåªä¿ç•™æŒ‡å®šç±»åˆ«
    detections = []
    if results[0].boxes is not None:
        boxes = results[0].boxes
        for i in range(len(boxes)):
            # è·å–è¾¹ç•Œæ¡†åæ ‡ (xyxyæ ¼å¼)
            x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
            confidence = boxes.conf[i].cpu().numpy()
            class_id = int(boxes.cls[i].cpu().numpy())
            class_name = yolo_model.names[class_id]
            
            # åªä¿ç•™ç›®æ ‡ç±»åˆ«
            if class_name in target_classes:
                detection = {
                    'bbox': [x1, y1, x2, y2],
                    'confidence': confidence,
                    'class_id': class_id,
                    'class_name': class_name,
                    'center': [(x1 + x2) / 2, (y1 + y2) / 2]
                }
                detections.append(detection)
    
    print(f"âœ… YOLOæ£€æµ‹ç»“æœ: {len(detections)} ä¸ª{target_classes}å¯¹è±¡")
    for i, det in enumerate(detections):
        print(f"   å¯¹è±¡ {i+1}: {det['class_name']} (ç½®ä¿¡åº¦: {det['confidence']:.3f})")
        print(f"           è¾¹ç•Œæ¡†: [{det['bbox'][0]:.0f}, {det['bbox'][1]:.0f}, {det['bbox'][2]:.0f}, {det['bbox'][3]:.0f}]")
        print(f"           ä¸­å¿ƒç‚¹: [{det['center'][0]:.0f}, {det['center'][1]:.0f}]")
    
    return detections

def test_sam2_segmentation(sam_predictor, image, detections):
    """ä½¿ç”¨YOLOæ£€æµ‹ç»“æœè¿›è¡ŒSAM2åˆ†å‰²"""
    print(f"\nğŸ“‹ Step 2: SAM2åˆ†å‰² (åŸºäº{len(detections)}ä¸ªYOLOæ£€æµ‹ç»“æœ)...")
    
    # è®¾ç½®å›¾åƒ
    sam_predictor.set_image(image)
    print("âœ… SAM2å›¾åƒè®¾ç½®å®Œæˆ")
    
    all_masks = []
    all_scores = []
    
    for i, detection in enumerate(detections):
        print(f"\n   å¤„ç†å¯¹è±¡ {i+1}: {detection['class_name']}")
        
        # æ–¹æ³•1: ä½¿ç”¨ä¸­å¿ƒç‚¹ä½œä¸ºprompt
        center_point = np.array([detection['center']], dtype=np.float32)
        center_label = np.array([1])  # å‰æ™¯ç‚¹
        
        try:
            # SAM2åˆ†å‰²
            masks, scores, logits = sam_predictor.predict(
                point_coords=center_point,
                point_labels=center_label,
                multimask_output=True,
            )
            
            # é€‰æ‹©æœ€ä½³mask
            best_mask_idx = scores.argmax()
            best_mask = masks[best_mask_idx]
            best_score = scores[best_mask_idx]
            
            all_masks.append(best_mask)
            all_scores.append(best_score)
            
            print(f"   âœ… åˆ†å‰²æˆåŠŸ: åˆ†æ•° {best_score:.3f}, maskå½¢çŠ¶ {best_mask.shape}")
            
        except Exception as e:
            print(f"   âŒ åˆ†å‰²å¤±è´¥: {e}")
            continue
    
    print(f"\nâœ… SAM2åˆ†å‰²å®Œæˆ: æˆåŠŸåˆ†å‰² {len(all_masks)} ä¸ªå¯¹è±¡")
    return all_masks, all_scores

def test_sam2_with_bbox_prompts(sam_predictor, image, detections):
    """ä½¿ç”¨è¾¹ç•Œæ¡†ä½œä¸ºSAM2çš„è¾“å…¥prompt"""
    print(f"\nğŸ“‹ Step 3: SAM2è¾¹ç•Œæ¡†åˆ†å‰²...")
    
    all_bbox_masks = []
    all_bbox_scores = []
    
    for i, detection in enumerate(detections):
        print(f"   å¤„ç†å¯¹è±¡ {i+1}è¾¹ç•Œæ¡†: {detection['class_name']}")
        
        # ä½¿ç”¨è¾¹ç•Œæ¡†ä½œä¸ºprompt
        bbox = np.array(detection['bbox'], dtype=np.float32)  # [x1, y1, x2, y2]
        
        try:
            # SAM2è¾¹ç•Œæ¡†åˆ†å‰²
            masks, scores, logits = sam_predictor.predict(
                box=bbox,
                multimask_output=False,  # è¾¹ç•Œæ¡†é€šå¸¸ç”¨å•mask
            )
            
            best_mask = masks[0]
            best_score = scores[0]
            
            all_bbox_masks.append(best_mask)
            all_bbox_scores.append(best_score)
            
            print(f"   âœ… è¾¹ç•Œæ¡†åˆ†å‰²æˆåŠŸ: åˆ†æ•° {best_score:.3f}")
            
        except Exception as e:
            print(f"   âŒ è¾¹ç•Œæ¡†åˆ†å‰²å¤±è´¥: {e}")
            continue
    
    print(f"\nâœ… è¾¹ç•Œæ¡†åˆ†å‰²å®Œæˆ: æˆåŠŸåˆ†å‰² {len(all_bbox_masks)} ä¸ªå¯¹è±¡")
    return all_bbox_masks, all_bbox_scores

def analyze_results(image, detections, point_masks, point_scores, bbox_masks, bbox_scores):
    """åˆ†æç»“æœ"""
    print(f"\nğŸ“Š ç»“æœåˆ†æ...")
    
    print(f"åŸå§‹å›¾åƒ: {image.shape}")
    print(f"YOLOæ£€æµ‹: {len(detections)} ä¸ªå¯¹è±¡")
    print(f"ç‚¹promptåˆ†å‰²: {len(point_masks)} ä¸ªmask")
    print(f"æ¡†promptåˆ†å‰²: {len(bbox_masks)} ä¸ªmask")
    
    # æ¯”è¾ƒä¸¤ç§æ–¹æ³•çš„åˆ†æ•°
    if point_scores and bbox_scores:
        avg_point_score = np.mean(point_scores)
        avg_bbox_score = np.mean(bbox_scores)
        
        print(f"\nåˆ†å‰²è´¨é‡æ¯”è¾ƒ:")
        print(f"  ç‚¹promptå¹³å‡åˆ†æ•°: {avg_point_score:.3f}")
        print(f"  æ¡†promptå¹³å‡åˆ†æ•°: {avg_bbox_score:.3f}")
        print(f"  {'æ¡†promptæ›´ä¼˜' if avg_bbox_score > avg_point_score else 'ç‚¹promptæ›´ä¼˜'}")
    
    # åˆ†æmaskè¦†ç›–åº¦
    if point_masks:
        total_pixels = image.shape[0] * image.shape[1]
        for i, mask in enumerate(point_masks):
            mask_pixels = np.sum(mask)
            coverage = mask_pixels / total_pixels * 100
            print(f"  å¯¹è±¡{i+1}ç‚¹maskè¦†ç›–: {coverage:.1f}%")
    
    if bbox_masks:
        for i, mask in enumerate(bbox_masks):
            mask_pixels = np.sum(mask)
            coverage = mask_pixels / total_pixels * 100
            print(f"  å¯¹è±¡{i+1}æ¡†maskè¦†ç›–: {coverage:.1f}%")

def save_visualization(image, detections, point_masks, bbox_masks, output_name="yolo_sam2_test_result.jpg"):
    """ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆå¿«é€Ÿä¿®å¤ç‰ˆï¼‰"""
    print(f"\nğŸ’¾ ä¿å­˜å¯è§†åŒ–ç»“æœ...")
    
    try:
        # åœ¨æ£€æµ‹æ¡†ä¸Šç»˜åˆ¶ç»“æœ
        vis_image = image.copy()
        
        # ç»˜åˆ¶YOLOæ£€æµ‹æ¡†
        for i, det in enumerate(detections):
            x1, y1, x2, y2 = [int(x) for x in det['bbox']]
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 255), 2)  # é»„è‰²æ¡†
            cv2.putText(vis_image, f"{det['class_name']}: {det['confidence']:.2f}", (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        # å¦‚æœæœ‰masksï¼Œå åŠ æ˜¾ç¤º - ä¿®å¤ç‰ˆ
        if point_masks:
            for i, mask in enumerate(point_masks):
                # å…³é”®ä¿®å¤ï¼šç¡®ä¿maskæ˜¯booleanç±»å‹
                mask_bool = mask.astype(bool)
                
                # åˆ›å»ºå½©è‰²mask
                color_mask = np.zeros_like(vis_image)
                color = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
                mask_color = color[i % len(color)]
                color_mask[mask_bool] = mask_color  # ä½¿ç”¨boolean mask
                
                # é€æ˜å åŠ 
                vis_image = cv2.addWeighted(vis_image, 0.8, color_mask, 0.2, 0)
        
        # ä¿å­˜ç»“æœ
        success = cv2.imwrite(output_name, vis_image)
        if success:
            print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_name}")
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç¡®å®å­˜åœ¨
            if os.path.exists(output_name):
                file_size = os.path.getsize(output_name)
                print(f"âœ… æ–‡ä»¶ç¡®è®¤å­˜åœ¨: {output_name} ({file_size:,} bytes)")
            else:
                print(f"âš ï¸ æ–‡ä»¶ä¿å­˜åä¸å­˜åœ¨: {output_name}")
        else:
            print(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {output_name}")
        
    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–ä¿å­˜å¤±è´¥: {e}")
        # ä¿å­˜ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬
        try:
            simple_vis = image.copy()
            for i, det in enumerate(detections):
                x1, y1, x2, y2 = [int(x) for x in det['bbox']]
                cv2.rectangle(simple_vis, (x1, y1), (x2, y2), (0, 255, 255), 2)
            
            simple_name = f"simple_{output_name}"
            cv2.imwrite(simple_name, simple_vis)
            print(f"âœ… ç®€åŒ–ç‰ˆæœ¬å·²ä¿å­˜: {simple_name}")
        except:
            print("âŒ ç®€åŒ–ç‰ˆæœ¬ä¿å­˜ä¹Ÿå¤±è´¥")
            
def test_real_image_yolo_sam2(image_path="../data/video_composed_frames/train/fgr/0000/frames/0088.png"):
    """æµ‹è¯•çœŸå®å›¾åƒçš„YOLO->SAM2æµç¨‹"""
    print("ğŸ” çœŸå®å›¾åƒ YOLO -> SAM2 æµ‹è¯•")
    print("="*60)
    print(f"ğŸ“ ç›®æ ‡å›¾åƒ: {image_path}")
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        yolo_model, sam_predictor = load_models()
        
        # 2. åŠ è½½çœŸå®å›¾åƒ
        real_image = load_real_image(image_path)
        if real_image is None:
            print("âŒ æ— æ³•åŠ è½½å›¾åƒï¼Œé€€å‡ºæµ‹è¯•")
            return
        
        # 3. YOLOæ£€æµ‹ï¼ˆåªæ£€æµ‹personï¼‰
        detections = test_yolo_detection_with_filter(yolo_model, real_image, target_classes=['person'])
        
        if not detections:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•personå¯¹è±¡")
            print("ğŸ“‹ å°è¯•æ£€æµ‹æ‰€æœ‰å¯¹è±¡ç±»åˆ«...")
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°personï¼Œæ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹ç»“æœ
            all_detections = test_yolo_detection_with_filter(yolo_model, real_image, 
                                                           target_classes=list(yolo_model.names.values()))
            if all_detections:
                print("æ£€æµ‹åˆ°çš„å…¶ä»–å¯¹è±¡:")
                unique_classes = set([det['class_name'] for det in all_detections])
                print(f"ç±»åˆ«: {', '.join(unique_classes)}")
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­ç”¨å…¶ä»–ç±»åˆ«æµ‹è¯•
                print("æ˜¯å¦ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¬¬ä¸€ä¸ªå¯¹è±¡è¿›è¡ŒSAM2æµ‹è¯•ï¼Ÿ")
                detections = [all_detections[0]]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹ç»“æœ
            else:
                print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼Œé€€å‡ºæµ‹è¯•")
                return
        
        # 4. SAM2åˆ†å‰² - ç‚¹prompt
        point_masks, point_scores = test_sam2_segmentation(sam_predictor, real_image, detections)
        
        # 5. SAM2åˆ†å‰² - è¾¹ç•Œæ¡†prompt
        bbox_masks, bbox_scores = test_sam2_with_bbox_prompts(sam_predictor, real_image, detections)
        
        # 6. åˆ†æç»“æœ
        analyze_results(real_image, detections, point_masks, point_scores, bbox_masks, bbox_scores)
        
        # 7. ä¿å­˜å¯è§†åŒ–ï¼ˆä½¿ç”¨ç‰¹æ®Šæ–‡ä»¶åï¼‰
        output_name = f"real_image_yolo_sam2_result_{os.path.basename(image_path)}"
        save_visualization(real_image, detections, point_masks, bbox_masks, output_name)
        
        print("\n" + "="*60)
        print("ğŸ‰ çœŸå®å›¾åƒ YOLO -> SAM2 æµ‹è¯•å®Œæˆ!")
        print(f"âœ… å¤„ç†å›¾åƒ: {image_path}")
        print(f"âœ… æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡å¯¹è±¡")
        print(f"âœ… æˆåŠŸåˆ†å‰² {len(point_masks)} ä¸ªå¯¹è±¡")
        print(f"âœ… ç»“æœä¿å­˜: {output_name}")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ çœŸå®å›¾åƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” YOLO -> SAM2 å®Œæ•´æµç¨‹é›†æˆæµ‹è¯•")
    print("="*60)
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    print("è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. çœŸå®å›¾åƒæµ‹è¯• (../data/video_composed_frames/train/fgr/0000/frames/0088.png)")
    print("2. ç”Ÿæˆå›¾åƒæµ‹è¯•")
    print("3. ä¸¤ç§éƒ½æµ‹è¯•")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤1): ").strip() or "1"
    
    if choice in ["1", "3"]:
        print("\n" + "ğŸ” å¼€å§‹çœŸå®å›¾åƒæµ‹è¯•" + "="*40)
        test_real_image_yolo_sam2()
    
    if choice in ["2", "3"]:
        print("\n" + "ğŸ” å¼€å§‹ç”Ÿæˆå›¾åƒæµ‹è¯•" + "="*40)
        run_synthetic_test()

def run_synthetic_test():
    """è¿è¡ŒåŸæ¥çš„åˆæˆå›¾åƒæµ‹è¯•"""
    try:
        # 1. åŠ è½½æ¨¡å‹
        yolo_model, sam_predictor = load_models()
        
        # 2. åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = create_test_image_with_objects()
        
        # 3. YOLOæ£€æµ‹
        detections = test_yolo_detection_with_filter(yolo_model, test_image, 
                                                   target_classes=list(yolo_model.names.values()))
        
        if not detections:
            print("âš ï¸ YOLOæœªæ£€æµ‹åˆ°å¯¹è±¡ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ£€æµ‹ç»“æœ...")
            detections = [{
                'bbox': [100, 200, 250, 350],
                'confidence': 0.85,
                'class_id': 0,
                'class_name': 'test_object',
                'center': [175, 275]
            }]
        
        # 4. SAM2åˆ†å‰² - ç‚¹prompt
        point_masks, point_scores = test_sam2_segmentation(sam_predictor, test_image, detections)
        
        # 5. SAM2åˆ†å‰² - è¾¹ç•Œæ¡†prompt
        bbox_masks, bbox_scores = test_sam2_with_bbox_prompts(sam_predictor, test_image, detections)
        
        # 6. åˆ†æç»“æœ
        analyze_results(test_image, detections, point_masks, point_scores, bbox_masks, bbox_scores)
        
        # 7. ä¿å­˜å¯è§†åŒ–
        save_visualization(test_image, detections, point_masks, bbox_masks, "synthetic_yolo_sam2_result.jpg")
        
        print("\n" + "="*60)
        print("ğŸ‰ ç”Ÿæˆå›¾åƒ YOLO -> SAM2 æµ‹è¯•å®Œæˆ!")
        print("âœ… å®Œæ•´æµç¨‹å·¥ä½œæ­£å¸¸")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå›¾åƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()