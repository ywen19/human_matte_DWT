#!/bin/bash

set -e

echo "å®Œæˆ SAM2 + YOLO çŽ¯å¢ƒé…ç½®..."

# æ¿€æ´»çŽ¯å¢ƒ
eval "$(conda shell.bash hook)"
conda activate sam2_yolo

# è®¾ç½®CUDAçŽ¯å¢ƒå˜é‡
CONDA_ENV_PATH="/home/wy/anaconda3/envs/cuda118"
export CUDA_HOME="$CONDA_ENV_PATH"
export PATH="$CUDA_HOME/bin:$PATH"
export LD_LIBRARY_PATH="$CONDA_ENV_PATH/lib64:$CONDA_ENV_PATH/lib:$LD_LIBRARY_PATH"

echo "å½“å‰çŽ¯å¢ƒ: $(which python)"
echo "CUDA_HOME: $CUDA_HOME"

# æ£€æŸ¥å¹¶å®‰è£… SAM2
if [ -d "sam2" ]; then
    echo "å‘çŽ°å·²å­˜åœ¨çš„ SAM2 ç›®å½•..."
    read -p "æ˜¯å¦é‡æ–°å…‹éš†å¹¶å®‰è£… SAM2? (y/N): " reinstall_sam2
    if [[ $reinstall_sam2 =~ ^[Yy]$ ]]; then
        echo "åˆ é™¤çŽ°æœ‰ SAM2 ç›®å½•..."
        rm -rf sam2
        echo "é‡æ–°å…‹éš† SAM2..."
        git clone https://github.com/facebookresearch/sam2.git
    fi
else
    echo "å…‹éš† SAM2 ä»“åº“..."
    git clone https://github.com/facebookresearch/sam2.git
fi

# å®‰è£… SAM2
echo "å®‰è£… SAM2..."
cd sam2
pip install -e . --no-deps  # ä½¿ç”¨ --no-deps é¿å…ç‰ˆæœ¬å†²çª
cd ..

# æµ‹è¯• SAM2 å¯¼å…¥
echo "æµ‹è¯• SAM2 å¯¼å…¥..."
python -c "
try:
    from sam2.build_sam import build_sam2
    from sam2.sam2_image_predictor import SAM2ImagePredictor
    print('âœ… SAM2 å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ SAM2 å¯¼å…¥å¤±è´¥: {e}')
    print('å°è¯•å®‰è£…ç¼ºå¤±çš„ä¾èµ–...')
    exit(1)
except Exception as e:
    print(f'âš ï¸  SAM2 å¯¼å…¥è­¦å‘Š: {e}')
    print('å¯èƒ½éœ€è¦ä¸‹è½½æ¨¡åž‹æ–‡ä»¶ï¼Œä½†åŸºæœ¬åŠŸèƒ½æ­£å¸¸')
"

# æµ‹è¯• YOLO
echo "æµ‹è¯• YOLO..."
python -c "
try:
    from ultralytics import YOLO
    import numpy as np
    import torch

    print('åˆå§‹åŒ– YOLO æ¨¡åž‹...')
    model = YOLO('yolov8n.pt')  # ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡åž‹
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)

    print('è¿è¡Œ YOLO CPU æŽ¨ç†...')
    results = model(test_img, verbose=False)
    print('âœ… YOLO CPU æµ‹è¯•é€šè¿‡')

    # æµ‹è¯•GPUæŽ¨ç†
    if torch.cuda.is_available():
        print('æµ‹è¯• YOLO GPU æŽ¨ç†...')
        try:
            model = model.to('cuda:0')
            results_gpu = model(test_img, device='cuda:0', verbose=False)
            print('âœ… YOLO GPU æµ‹è¯•é€šè¿‡')
        except Exception as e:
            print(f'âš ï¸  YOLO GPU æµ‹è¯•å¤±è´¥: {e}')
            print('CPU æ¨¡å¼ä»ç„¶å¯ç”¨')

except Exception as e:
    print(f'âŒ YOLO æµ‹è¯•å¤±è´¥: {e}')
    exit(1)
"

# åˆ›å»ºæµ‹è¯•è„šæœ¬
echo "åˆ›å»ºæµ‹è¯•è„šæœ¬..."
cat > test_environment.py << 'EOF'
#!/usr/bin/env python3
"""
SAM2 + YOLO çŽ¯å¢ƒæµ‹è¯•è„šæœ¬
"""

import torch
import numpy as np
import cv2
import sys
import os

def test_basic_imports():
    """æµ‹è¯•åŸºæœ¬åº“å¯¼å…¥"""
    print("=== åŸºæœ¬åº“æµ‹è¯• ===")
    try:
        print(f"âœ… Python: {sys.version}")
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… NumPy: {np.__version__}")
        print(f"âœ… OpenCV: {cv2.__version__}")
        return True
    except Exception as e:
        print(f"âŒ åŸºæœ¬åº“å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_cuda():
    """æµ‹è¯•CUDAæ”¯æŒ"""
    print("\n=== CUDA æµ‹è¯• ===")
    try:
        print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
            for i in range(min(torch.cuda.device_count(), 4)):
                print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            
            # æµ‹è¯•CUDAå¼ é‡æ“ä½œ
            x = torch.randn(1000, 1000, device='cuda:0')
            y = torch.matmul(x, x.T)
            print("âœ… CUDA å¼ é‡æ“ä½œæ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ CUDA æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_yolo():
    """æµ‹è¯•YOLO"""
    print("\n=== YOLO æµ‹è¯• ===")
    try:
        from ultralytics import YOLO
        
        # åˆå§‹åŒ–æ¨¡åž‹
        model = YOLO('yolov8n.pt')
        print("âœ… YOLO æ¨¡åž‹åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # CPUæŽ¨ç†
        results = model(test_img, verbose=False)
        print("âœ… YOLO CPU æŽ¨ç†æˆåŠŸ")
        
        # GPUæŽ¨ç†ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            try:
                model_gpu = YOLO('yolov8n.pt').to('cuda:0')
                results_gpu = model_gpu(test_img, device='cuda:0', verbose=False)
                print("âœ… YOLO GPU æŽ¨ç†æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸  YOLO GPU æŽ¨ç†å¤±è´¥: {e}")
        
        return True
    except Exception as e:
        print(f"âŒ YOLO æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_sam2():
    """æµ‹è¯•SAM2"""
    print("\n=== SAM2 æµ‹è¯• ===")
    try:
        # å°è¯•å¯¼å…¥SAM2
        from sam2.build_sam import build_sam2
        from sam2.sam2_image_predictor import SAM2ImagePredictor
        print("âœ… SAM2 æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æ³¨æ„ï¼šå®žé™…ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡åž‹æ–‡ä»¶
        print("âš ï¸  SAM2 éœ€è¦ä¸‹è½½æ¨¡åž‹æ–‡ä»¶æ‰èƒ½å®Œå…¨æµ‹è¯•")
        print("   æ¨¡åž‹ä¸‹è½½å‘½ä»¤ï¼š")
        print("   cd sam2/checkpoints && ./download_ckpts.sh")
        
        return True
    except Exception as e:
        print(f"âŒ SAM2 æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_integration():
    """æµ‹è¯•é›†æˆåŠŸèƒ½"""
    print("\n=== é›†æˆæµ‹è¯• ===")
    try:
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # OpenCVå¤„ç†
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        
        # NumPy-PyTorchè½¬æ¢
        img_tensor = torch.from_numpy(img.transpose(2, 0, 1)).float() / 255.0
        
        if torch.cuda.is_available():
            img_gpu = img_tensor.cuda()
            img_cpu = img_gpu.cpu().numpy()
        
        print("âœ… å›¾åƒå¤„ç†å’Œå¼ é‡è½¬æ¢æ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ðŸš€ å¼€å§‹çŽ¯å¢ƒæµ‹è¯•...\n")
    
    tests = [
        test_basic_imports,
        test_cuda,
        test_yolo,
        test_sam2,
        test_integration
    ]
    
    results = []
    for test in tests:
        results.append(test())
    
    print("\n" + "="*50)
    print("ðŸ“Š æµ‹è¯•ç»“æžœæ±‡æ€»:")
    print("="*50)
    
    if all(results):
        print("ðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼çŽ¯å¢ƒé…ç½®æˆåŠŸï¼")
        print("\nðŸ“‹ çŽ¯å¢ƒä¿¡æ¯:")
        print(f"   - Python: {sys.version.split()[0]}")
        print(f"   - PyTorch: {torch.__version__}")
        print(f"   - CUDA: {torch.cuda.is_available()}")
        print(f"   - GPUæ•°é‡: {torch.cuda.device_count() if torch.cuda.is_available() else 0}")
        
        print("\nðŸš€ å¼€å§‹ä½¿ç”¨:")
        print("1. æ¿€æ´»çŽ¯å¢ƒ: conda activate sam2_yolo")
        print("2. è®¾ç½®çŽ¯å¢ƒå˜é‡: ")
        print(f"   export CUDA_HOME={os.environ.get('CUDA_HOME', '/path/to/cuda')}")
        print("3. ä¸‹è½½SAM2æ¨¡åž‹: cd sam2/checkpoints && ./download_ckpts.sh")
        
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        failed_tests = [i for i, result in enumerate(results) if not result]
        print(f"å¤±è´¥çš„æµ‹è¯•: {failed_tests}")
EOF

# è¿è¡Œæµ‹è¯•
echo "è¿è¡Œå®Œæ•´çŽ¯å¢ƒæµ‹è¯•..."
python test_environment.py

echo ""
echo "ðŸŽ‰ SAM2 + YOLO çŽ¯å¢ƒé…ç½®å®Œæˆï¼"
echo ""
echo "ðŸ“ é¡¹ç›®ç»“æž„ï¼š"
echo "   $(pwd)/"
echo "   â”œâ”€â”€ sam2/                    # SAM2 æºç "
echo "   â”œâ”€â”€ test_environment.py     # çŽ¯å¢ƒæµ‹è¯•è„šæœ¬"
echo "   â””â”€â”€ ä½ çš„é¡¹ç›®æ–‡ä»¶..."
echo ""
echo "ðŸš€ ä¸‹ä¸€æ­¥ï¼š"
echo "1. ä¸‹è½½ SAM2 æ¨¡åž‹:"
echo "   cd sam2/checkpoints"
echo "   ./download_ckpts.sh"
echo ""
echo "2. å¼€å§‹å¼€å‘ä½ çš„é¡¹ç›®ï¼"